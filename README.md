# Interactive-design-with-Ableton-with-Kinect
This code is made in collaboration with https://github.com/mikkelmedm in Oktober 2013.

This code uses the Skeleton tracking library for Processing to track body movements with a Microsoft Kinect camera. 
Using the promidi library to generate midi signals captured by Ableton live. 
Ableton Live runs Max for live and uses VIZZable presets to manipulate real-time video. 

The user is able to control the music which controls a responsive video by moving their hand to visual 'boxes'. 

